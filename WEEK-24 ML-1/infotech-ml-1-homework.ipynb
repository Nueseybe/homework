{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# INFOTECH ACADEMY MACHINE LEARNING-1 HOMEWORK","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n    ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-04T12:01:47.888763Z","iopub.execute_input":"2023-06-04T12:01:47.889165Z","iopub.status.idle":"2023-06-04T12:01:47.898270Z","shell.execute_reply.started":"2023-06-04T12:01:47.889134Z","shell.execute_reply":"2023-06-04T12:01:47.897145Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/titanic_dataset.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Load Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/titanic/titanic_dataset.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-04T12:02:23.712436Z","iopub.execute_input":"2023-06-04T12:02:23.712832Z","iopub.status.idle":"2023-06-04T12:02:23.786313Z","shell.execute_reply.started":"2023-06-04T12:02:23.712799Z","shell.execute_reply":"2023-06-04T12:02:23.785048Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0 PassengerId HomePlanet CryoSleep  Cabin  Destination   Age  \\\n0           0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0   \n1           1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0   \n2           2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   \n3           3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0   \n4           4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0   \n\n     VIP  RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  \\\n0  False          0.0        0.0           0.0     0.0     0.0   \n1  False        109.0        9.0          25.0   549.0    44.0   \n2   True         43.0     3576.0           0.0  6715.0    49.0   \n3  False          0.0     1283.0         371.0  3329.0   193.0   \n4  False        303.0       70.0         151.0   565.0     2.0   \n\n                Name  Transported  \n0    Maham Ofracculy        False  \n1       Juanna Vines         True  \n2      Altark Susent        False  \n3       Solam Susent        False  \n4  Willy Santantines         True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>PassengerId</th>\n      <th>HomePlanet</th>\n      <th>CryoSleep</th>\n      <th>Cabin</th>\n      <th>Destination</th>\n      <th>Age</th>\n      <th>VIP</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n      <th>Name</th>\n      <th>Transported</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0001_01</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>B/0/P</td>\n      <td>TRAPPIST-1e</td>\n      <td>39.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Maham Ofracculy</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0002_01</td>\n      <td>Earth</td>\n      <td>False</td>\n      <td>F/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>24.0</td>\n      <td>False</td>\n      <td>109.0</td>\n      <td>9.0</td>\n      <td>25.0</td>\n      <td>549.0</td>\n      <td>44.0</td>\n      <td>Juanna Vines</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0003_01</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>58.0</td>\n      <td>True</td>\n      <td>43.0</td>\n      <td>3576.0</td>\n      <td>0.0</td>\n      <td>6715.0</td>\n      <td>49.0</td>\n      <td>Altark Susent</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0003_02</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>33.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1283.0</td>\n      <td>371.0</td>\n      <td>3329.0</td>\n      <td>193.0</td>\n      <td>Solam Susent</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0004_01</td>\n      <td>Earth</td>\n      <td>False</td>\n      <td>F/1/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>16.0</td>\n      <td>False</td>\n      <td>303.0</td>\n      <td>70.0</td>\n      <td>151.0</td>\n      <td>565.0</td>\n      <td>2.0</td>\n      <td>Willy Santantines</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Step 1: Define the Problem\n\nClearly define the problem you want to solve using the Titanic dataset. For example, you could predict whether a passenger survived or not based on various features.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2: Gather and Explore the Data\n\nObtain the Titanic dataset from a reliable source, such as Kaggle.\nExplore the dataset to understand its structure and variables.\nIdentify the features that are available and their potential relevance to the problem.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3: Preprocess the Data\n\n* Handle missing values by imputing or removing them appropriately.\n* Detect and handle outliers using techniques such as:\n    - **Visualization** : Plot box plots or histograms to identify potential outliers.\n    - **Statistical methods**: Calculate z-scores or interquartile ranges to identify and handle outliers.\n* Transform categorical variables into numerical representations (e.g., one-hot encoding).\n* Normalize or scale numerical features as needed.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 4: Check for Normality\n\nPerform a normality check on the numerical features to assess if they follow a Gaussian distribution.\nUse techniques like histograms, Q-Q plots, or statistical tests (e.g., Shapiro-Wilk test) to check for normality.\n\nIf the data is not normally distributed, consider applying appropriate transformations.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 5: Apply Transformations\n\nApply transformations to the data if required, based on the normality check results.\n\nCommon transformations include:\n\n* Logarithmic transformation: Use when data is positively skewed.\n* Square root transformation: Use when data has a moderate positive skew.\n* Power transformation: Use when data has a severe positive or negative skew.\n\nApply the chosen transformation(s) to the appropriate features.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 6: Split the Data\n\nSplit the preprocessed and transformed data into training and testing sets.\nTypically, use around 70-80% of the data for training and the remaining for testing.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 7: Select a Suitable Algorithm\n\nDetermine the appropriate algorithm(s) for this binary classification problem.\nConsider algorithms like **Logistic Regression, Decision Trees, Random Forests, or Support Vector Machines.**\nChoose an algorithm that suits the problem requirements and constraints.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 8: Train the Model\n\nTrain the selected algorithm on the training dataset.\nAdjust hyperparameters if necessary to optimize model performance.\nEvaluate the model's performance using suitable metrics (accuracy, precision, recall, etc.).","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 9: Validate the Model\n\nUse the testing dataset to validate the model's performance.\nCalculate the same metrics as in step 8 to assess the model's accuracy and generalization ability.\nIdentify any issues like overfitting or underfitting.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 10: Fine-tune and Optimize the Model\n\nIf needed, fine-tune the model by adjusting hyperparameters or trying different algorithms.\nEmploy techniques like cross-validation or grid search to find the best hyperparameters.\nIterate this process until you achieve satisfactory performance.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 11: Evaluate the Final Model\n\nEvaluate the final model on the testing dataset once again.\nCalculate relevant metrics to assess the model's accuracy, precision, recall, etc.\nInterpret the model's predictions and document the results.\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 12: Communicate the Findings\n\nPrepare a report or presentation summarizing the project's objectives, methodology, and results.\nClearly communicate the insights gained from the model, such as the importance of different features in predicting survival.\nProvide recommendations or potential applications based on the findings.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 13: Reflect and Learn\n\nReflect on the entire process and discuss the strengths and limitations of the project.\nIdentify areas for improvement and suggest future work or possible enhancements.\nShare any lessons learned from the project to inform future endeavors.\nRemember, adapt this guide based on the specific requirements and learning goals of your charity data bootcamp organization.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}